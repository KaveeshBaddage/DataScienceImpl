{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Information Retrieval – Assignment 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOhuDORNMQBRfqxlHlbxSzz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaveeshBaddage/DataScienceImpl/blob/main/Information_Retrieval_%E2%80%93_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lblfiO0jPMPg"
      },
      "source": [
        "**Get Content from text files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpOC9gUH2JIm"
      },
      "source": [
        "def read_file(filename):\n",
        "    input_file = open(filename)\n",
        "    input_file_content = input_file.read()\n",
        "    input_file.close()\n",
        "    return input_file_content"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1X5KxwUPR4s"
      },
      "source": [
        "**Read contents in the text files into the runtime**\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqlqjtamNRdH"
      },
      "source": [
        "student_feedback_content =  read_file(\"/content/Student Course Feedback.txt\") \n",
        "twitter_content = read_file(\"/content/Twitter Data.txt\")\n",
        "research_paper_content = read_file(\"/content/research paper.txt\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cMHA-sRPffz"
      },
      "source": [
        "**Tokenize the Content**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ5UGVOJOjLX",
        "outputId": "14031567-7cb2-4c2f-c314-2dfca3f7eb30"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize\n",
        "\n",
        "tokenized_student_feedback_content = word_tokenize(student_feedback_content)\n",
        "tokenized_twitter_content = word_tokenize(twitter_content)\n",
        "tokenized_research_paper_content = word_tokenize(research_paper_content)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVmGth5oRTKH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "793c56d0-7d8a-4909-fcd9-0a754e44a1e0"
      },
      "source": [
        "print(\"-------------------  Tokkenized Student feedback content   --------------------\")\n",
        "print(\"------------------------------------------------------------------------------- \\n\")\n",
        "print(tokenized_student_feedback_content ,\"\\n\" )\n",
        "print(\"-------------------  Tokkenized Twitter content   --------------------\")\n",
        "print(\"------------------------------------------------------------------------------- \\n\")\n",
        "print(tokenized_twitter_content , \"\\n\")\n",
        "print(\"-------------------  Tokkenized Research paper content   --------------------\")\n",
        "print(\"------------------------------------------------------------------------------- \\n\")\n",
        "print(tokenized_research_paper_content , \"\\n\")"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------  Tokkenized Student feedback content   --------------------\n",
            "------------------------------------------------------------------------------- \n",
            "\n",
            "['Honestly', 'last', 'seven', 'lectures', 'are', 'good', '.', 'Lectures', 'are', 'understandable', '.', 'Lecture', 'slides', 'are', 'very', 'useful', 'to', 'self-study', 'also', '.', 'The', 'given', 'opportunity', 'to', 'ask', 'questions', 'from', 'the', 'lecturer', 'is', 'appreciative', '.', '``', 'Good', ':', ')', '<', 'br', '/', '>', 'please', 'do', 'recap', 'at', 'class', 'starting', 'it', '&', '#', '039', ';', 's', 'better', 'for', 'us', '.', '<', 'br', '/', '>', 'sometimes', 'teaching', 'speed', 'is', 'very', 'high', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'Thanks', '!', ':', ')', '<', 'br', '/', '>', '``', 'The', 'lectures', 'are', 'good..but', 'a', 'bit', 'speed.A', 'in', 'class', 'working', 'activity', 'is', 'a', 'must', 'one.So', 'please', 'take', 'another', 'hour', 'in', 'thursdays', 'madame.', \"''\", '<', 'br', '/', '>', 'We', 'can', 'hear', 'your', 'voice', 'clearly', 'and', 'can', 'understand', 'the', 'things', 'you', 'teach', '.', 'Presentation', 'slides', 'also', 'good', 'source', 'to', 'refer', '.', 'lf', 'you', 'can', 'do', 'more', 'example', 'questions', 'within', 'the', 'classroom', 'and', 'it', 'will', 'help', 'us', 'to', 'understand', 'the', 'principles', 'well', '.', '<', 'br', '/', '>', \"''\", 'Lectures', 'was', 'well', 'structured', 'and', 'well', 'organized', '.', 'It', 'was', 'easy', 'to', 'understand', '.', 'Lecture', 'slides', 'and', 'labs', 'were', 'also', 'well', 'organized', '.', 'Lectures', 'were', 'good', '.', 'understandable', '.', 'The', 'lecture', 'slides', 'were', 'well', 'organized', 'and', 'the', 'examples', 'done', 'in', 'the', 'class', 'helped', 'a', 'lot', 'to', 'learn', 'this', 'new', 'language', 'and', 'also', 'the', 'principles', 'of', 'OOP', '.', 'Motivated', 'to', 'well', '.', 'Would', 'have', 'been', 'better', 'if', 'we', 'discussed', 'more', 'about', 'the', 'solutions', 'of', 'coding', 'exercisers', '.', 'I', 'think', 'i', 'learned', 'a', 'lot', 'from', 'the', 'codes', 'you', 'write', 'in', 'the', 'board', '.', 'When', 'i', 'compare', 'my', 'codes', 'with', 'yours', 'i', 'can', 'learn', 'about', 'my', 'mistakes', 'and', 'good', 'coding', 'practices', 'that', 'i', 'should', 'follow', '.', 'There', 'fore', 'i', 'think', 'it', 'would', 'be', 'great', 'if', 'we', 'can', 'discuss', 'more', 'examples', 'in', 'the', 'class', '.', 'madam', 'explained', 'the', 'oop', 'concepts', 'clearly', 'with', 'examples.lectures', 'were', 'interesting.we', 'want', 'more', 'scenario', 'examples', 'and', 'answers', 'with', 'explanations', 'in', 'future', '.', 'I', 'satisfy', 'about', 'first', '7', 'lectures', '.', 'That', 'way', 'of', 'teaching', 'is', 'really', 'good', 'for', 'coming', 'lectures', 'too', '.', 'lectuers', 'are', 'very', 'good', '.', 'take', 'good', 'effort', 'to', 'make', 'undersatand', 'every', 'student', 'in', 'the', 'room', '.', 'very', 'helpfull', '.', 'I', 'was', 'able', 'to', 'obtain', 'a', 'clear', 'picture', 'about', 'OOP', 'and', 'its', 'concepts', '.', '``', 'lecture', 'slides', ',', 'explanations', 'were', 'very', 'clear', '.', '<', 'br', '/', '>', 'it', '&', '#', '039', ';', 's', 'very', 'good', 'to', 'letting', 'ask', 'questions', 'and', 'explain', 'again', 'with', 'suitable', 'examples', '.', '<', 'br', '/', '>', 'sometimes', ',', 'some', 'codes', 'on', 'white', 'board', 'were', 'unclear', 'at', 'the', 'back', '.', '<', 'br', '/', '>', 'overall', 'very', 'good', '!', '!', '!', '<', 'br', '/', '>', \"''\", 'The', 'lectures', 'were', 'good', 'and', 'clear', '.', 'And', 'they', 'weren', '&', '#', '039', ';', 't', 'too', 'fast', '.', 'Writing', 'code', 'was', 'somewhat', 'confusing', 'because', 'I', 'didn', '&', '#', '039', ';', 't', 'know', 'java', 'before', '.', 'Actually', 'teaching', 'is', 'very', 'good', 'and', 'can', 'understand', 'easily', 'the', 'concepts', 'by', 'examples', 'which', 'are', 'given', 'in', 'the', 'class.it', 'will', 'be', 'more', 'helpful', 'if', 'provide', 'solved', 'questions', 'as', 'well', '!', '.', 'thankyou'] \n",
            "\n",
            "-------------------  Tokkenized Twitter content   --------------------\n",
            "------------------------------------------------------------------------------- \n",
            "\n",
            "['Reminds', 'me', 'of', 'Liberal', 'Immigration', 'Fraudster', 'Monsef', 'avoiding', 'deportation', 'from', 'Canada', '.', '#', 'cdnpoli', '#', 'LPC', '#', 'CPCLDR��_', 'https', ':', '//t.co/ZOZOSe1CqQ', '#', 'immigration', '#', 'integration', '#', 'canada', 'https', ':', '//t.co/M5cKGyvV8F', 'We', 'want', 'controlled', 'immigration', 'that', 'contributes', 'positively', 'to', 'the', 'UK', 'economy', '.', 'Same', 'as', 'Australia', '&', 'amp', ';', 'Canada', '.', 'https', ':', '//t.co/99mYliuOes', 'Is', 'the', 'new', 'Manitoba', 'immigration', 'fee', 'a', 'head', 'tax', '?', 'https', ':', '//t.co/LsG7C3vLe9', 'Canada', 'immigration', 'profit', 'influence', 'modernistic', 'delhi', 'yet', 'abhinav', ':', 'XKofy', 'https', ':', '//t.co/becgusY2i6', 'Canada', 'Immigration', 'Minister', 'to', '���Substantially', 'Increase', 'Immigration', 'Numbers', 'https', ':', '//t.co/nEFw30MRaa', 'https', ':', '//t.co/cyI867PZRV', 'M��me', 'les', '#', 'USA=pays', \"d'immigration\", 'par', 'excellence', 'CONTR��LE', 'RIGOUREUSEMENT', \"l'immigration\", 'et', 'acc��s', '��', 'la', '#', 'GreenCARD', '!', '��_', 'https', ':', '//t.co/IHpVhW2BaG', '@', 'Shawhelp', 'what', 'changes', 'should', 'be', 'made', 'to', 'Canada', \"'s\", 'immigration', 'laws', 'due', 'to', 'the', 'influx', 'of', 'immigration', 'and', 'violence', '?', 'L��immigration', 'irr��guli��re', 'au', 'Canada', 'd��cortiqu��e', 'en', '5', 'questions', 'https', ':', '//t.co/f4utO5A7ZF', \"L'immigration\", 'irr��guli��re', 'au', 'Canada', 'd��cortiqu��e', 'en', '5', 'questions', '-', 'https', ':', '//t.co/UiBsEZOqas', 'https', ':', '//t.co/j77dEvjoiX', 'https', ':', '//t.co/XXDeIG7Dbu', 'Will', 'Media', 'ask', 'the', 'Liberals', 'if', 'they', 'actually', 'have', 'a', 'solid', 'plan', 'for', 'Canada', '_��_�_', '?', '?', 'From', 'my', 'view', '--', 'immigration', 'out', 'of', 'C��_', 'https', ':', '//t.co/YAgwmZ8ECp', 'Dan', 'Murray', 'of��Immigration', 'Watch', 'Canada', 'is', 'xenophobic', 'racist', 'fear-mongering', 'liar', '#', 'racism', '#', 'canada', '#', 'cdnpoli', '#', 'hatecrime��_', 'https', ':', '//t.co/kwZ3csvYxM', 'Le', 'Canada', 'lance', 'une', 'vaste', 'campagne', \"d'immigration\", 'pour', 'faire', 'face', '��', 'son', 'besoin', 'de', 'main', \"d'��uvre\", 'https', ':', '//t.co/kXdfMGTZzN', 'L��', '#', 'immigration', 'irr��guli��re', 'au', '#', 'Canada', 'd��cortiqu��e', 'en', '5��questions', 'https', ':', '//t.co/s3hu1OKKIG', '@', 'Canadidly', 'I', \"'ve\", 'read', 'the', 'Immigration', 'laws', 'of', 'Canada', 'much', 'stricter', 'than', 'the', 'US', 'Canada', 'Immigration', 'Website', 'Traffic', 'Surges', 'And', 'Crashes', 'In', 'Wake', 'Of', 'Trump', '#', 'fasttraffic', ',', '#', 'sitetraffic', ',', '#', 'website', ',', '#', 'traffic', 'https', ':', '//t.co/zRlJ26jnkC', 'Mr', 'Know-all', 'of', 'Canada', 'Immigration', 'https', ':', '//t.co/wTQK4QDiKI', 'Move', 'to', 'Canada', '@', 'LadyMadonna___', 'Oh', ',', 'immigration', 'rules', ',', 'you', 'ca', \"n't\", '...', 'https', ':', '//t.co/5LIEVHO7A4', '#', 'OnThisDay', 'Annette', 'Toft', 'becomes', 'Canada', \"'s\", '2', 'millionth', 'immigrant', 'since', '1945', '.', 'Do', 'you', 'know', 'your', 'family', \"'s\", 'immigration', 'st��_', 'https', ':', '//t.co/UvRuw8eR1b', '.', '@', 'TheEconomist', 'profiles', 'Canada', \"'s\", 'open', 'immigration', 'policies', '&', 'amp', ';', 'how', 'they', 'contribute', 'to', 'our', 'economic', 'success', ':', '��_', 'https', ':', '//t.co/4K84EE8Y63', 'Hundreds', 'may', 'lose', 'Canadian', 'citizenship', ',', 'resident', 'status', 'because', 'of', 'one', 'corrupt', 'immigration', 'consultant', 'https', ':', '//t.co/x2IfO0EXI2', 'Immigration', 'for', 'canada', 'without', 'india', ':', 'an', 'compassionate', 'handle', ':', 'deyFy', \"''\", '#', 'Jamaican', '#', 'immigrants', '#', 'Canada', 'https', ':', '//t.co/vcmfYGadR5', '#', 'statistics', '#', 'immigration', \"''\", 'Mexican', 'visa', 'lift', 'expected', 'to', 'cost', 'Canada', '$', '262M', 'over', 'a', 'decade', 'https', ':', '//t.co/9i72fRhtij', 'Are', 'people', 'still', 'moving', 'to', '#', 'Canada', '?', '?', '?', 'Oh', 'that', \"'s\", 'right', ',', 'they', 'have', 'real', 'immigration', 'laws', 'and', \"it's��_\", 'https', ':', '//t.co/0C5OBfmxLG', 'Here', 'are', 'more', 'details', 'on', 'the', 'Richmond', ',', 'B.C', '.', 'Immigration', 'Consultant', 'Sunny', 'Wang', 'who', 'was', 'sentenced', 'to', '7', 'years', 'in', '...', 'https', ':', '//t.co/YXH5W53srO', 'I', 'added', 'a', 'video', 'to', 'a', '@', 'YouTube', 'playlist', 'https', ':', '//t.co/CnEyWN40x3', 'Funny', 'Talking', 'of', 'Haryanavi', 'Jat', 'with', 'Canada', 'Immigration', 'Girl', 'Agent', 'Mexicans', 'Can', 'Now', 'Travel', 'Visa-Free', 'To', 'Canada', 'https', ':', '//t.co/Ec3XHORO2s', 'https', ':', '//t.co/RQRr5nebcG', 'L��immigration', 'irr��guli��re', 'au', 'Canada', 'd��cortiqu��e', 'en', '5��questions', 'https', ':', '//t.co/DkpuKyWmaK', '@', 'SweetnessShawnB', 'Hes', 'the', 'POS', 'that', 'ramped', 'up', 'immigration', 'for', 'Canada', ',', 'among', 'other', 'globalist', 'policies', '.', 'Canada', 'lifted', 'visa', 'requirements', 'to', 'Mexico', 'as', 'of', 'Dec', '1', ',', '2016', '.', 'Thoughts', '?', '#', 'visa', '#', 'immigration', '@', 'HuffingtonPost', 'people', 'Keep', 'praising', 'Canada', 'and', 'Canada', 'has', 'way', 'stricter', 'immigration', 'laws', 'then', 'us', 'they', 'willl', 'boot', 'your', 'liberal', 'American', 'ass'] \n",
            "\n",
            "-------------------  Tokkenized Research paper content   --------------------\n",
            "------------------------------------------------------------------------------- \n",
            "\n",
            "['Neural', 'network', 'models', 'have', 'shown', 'their', 'promising', 'opportunities', 'for', 'multi-task', 'learning', ',', 'which', 'focus', 'on', 'learning', 'the', 'shared', 'layers', 'to', 'extract', 'the', 'common', 'and', 'task-invariant', 'features', '.', 'However', ',', 'in', 'most', 'existing', 'approaches', ',', 'the', 'extracted', 'shared', 'features', 'are', 'prone', 'to', 'be', 'contaminated', 'by', 'task-specific', 'features', 'or', 'the', 'noise', 'brought', 'by', 'other', 'tasks', '.', 'In', 'this', 'paper', ',', 'we', 'propose', 'an', 'adversarial', 'multi-task', 'learning', 'framework', ',', 'alleviating', 'the', 'shared', 'and', 'private', 'latent', 'feature', 'spaces', 'from', 'interfering', 'with', 'each', 'other', '.', 'We', 'conduct', 'extensive', 'experiments', 'on', '16', 'different', 'text', 'classification', 'tasks', ',', 'which', 'demonstrates', 'the', 'benefits', 'of', 'our', 'approach', '.', 'Besides', ',', 'we', 'show', 'that', 'the', 'shared', 'knowledge', 'learned', 'by', 'our', 'proposed', 'model', 'can', 'be', 'regarded', 'as', 'off-the-shelf', 'knowledge', 'and', 'easily', 'transferred', 'to', 'new', 'tasks', '.', 'Multi-task', 'learning', 'is', 'an', 'effective', 'approach', 'to', 'improve', 'the', 'performance', 'of', 'a', 'single', 'task', 'with', 'the', 'help', 'of', 'other', 'related', 'tasks', '.', 'Recently', ',', 'neural-based', 'models', 'for', 'multi-task', 'learning', 'have', 'become', 'very', 'popular', ',', 'ranging', 'from', 'computer', 'vision', '(', 'Misra', 'et', 'al.', ',', '2016', ';', 'Zhang', 'et', 'al.', ',', '2014', ')', 'to', 'natural', 'language', 'processing', '(', 'Collobert', 'andWeston', ',', '2008', ';', 'Luong', 'et', 'al.', ',', '2015', ')', ',', 'since', 'they', 'provide', 'a', 'convenient', 'way', 'of', 'combining', 'information', 'from', 'multiple', 'tasks', '.', 'However', ',', 'most', 'existing', 'work', 'on', 'multi-task', 'learning', '(', 'Liu', 'et', 'al.', ',', '2016c', ',', 'b', ')', 'attempts', 'to', 'divide', 'the', 'features', 'of', 'different', 'tasks', 'into', 'private', 'and', 'shared', 'spaces', ',', 'merely', 'based', 'on', 'whether', 'parameters', 'of', 'some', 'components', 'should', 'be', 'shared', '.', 'As', 'shown', 'in', 'Figure', '1-', '(', 'a', ')', ',', 'the', 'general', 'shared-private', 'model', 'introduces', 'two', 'feature', 'spaces', 'for', 'any', 'task', ':', 'one', 'is', 'used', 'to', 'store', 'task-dependent', 'features', ',', 'the', 'other', 'is', 'used', 'to', 'capture', 'shared', 'features', '.', 'The', 'major', 'limitation', 'of', 'this', 'framework', 'is', 'that', 'the', 'shared', 'feature', 'space', 'could', 'contain', 'some', 'unnecessary', 'task-specific', 'features', ',', 'while', 'some', 'sharable', 'features', 'could', 'also', 'be', 'mixed', 'in', 'private', 'space', ',', 'suffering', 'from', 'feature', 'redundancy', '.', 'Taking', 'the', 'following', 'two', 'sentences', 'as', 'examples', ',', 'which', 'are', 'extracted', 'from', 'two', 'different', 'sentiment', 'classification', 'tasks', ':', 'Movie', 'reviews', 'and', 'Baby', 'products', 'reviews', '.', 'The', 'infantile', 'cart', 'is', 'simple', 'and', 'easy', 'to', 'use', '.', 'This', 'kind', 'of', 'humour', 'is', 'infantile', 'and', 'boring', '.', 'The', 'word', '�infantile�', 'indicates', 'negative', 'sentiment', 'in', 'Movie', 'task', 'while', 'it', 'is', 'neutral', 'in', 'Baby', 'task', '.', 'However', ',', 'the', 'general', 'shared-private', 'model', 'could', 'place', 'the', 'task-specific', 'word', '�infantile�', 'in', 'a', 'shared', 'space', ',', 'leaving', 'potential', 'hazards', 'for', 'other', 'tasks', '.', 'Additionally', ',', 'the', 'capacity', 'of', 'shared', 'space', 'could', 'also', 'be', 'wasted', 'by', 'some', 'unnecessary', 'features', '.', 'To', 'address', 'this', 'problem', ',', 'in', 'this', 'paper', 'we', 'propose', 'an', 'adversarial', 'multi-task', 'framework', ',', 'in', 'which', 'the', 'shared', 'and', 'private', 'feature', 'spaces', 'are', 'in', 'herently', 'disjoint', 'by', 'introducing', 'orthogonality', 'constraints.Specifically', ',', 'we', 'design', 'a', 'generic', 'shared', 'private', 'learning', 'framework', 'to', 'model', 'the', 'text', 'sequence', '.'] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoVsbIQBDo7P"
      },
      "source": [
        "## **Context sensitive word correction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qjRwzW5ADkKz",
        "outputId": "0f66e9c1-3f89-4f72-b3ce-07efe850e4f4"
      },
      "source": [
        "#required libraries for context sensitive Spell checker\n",
        "!pip install neuspell\n",
        "from neuspell import SclstmChecker\n",
        "checker = SclstmChecker()\n",
        "\n",
        "checker.from_pretrained()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting neuspell\n",
            "  Downloading neuspell-1.0.0-py3-none-any.whl (184 kB)\n",
            "\u001b[K     |████████████████████████████████| 184 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting pytorch-pretrained-bert\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 49.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from neuspell) (4.62.3)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from neuspell) (1.9.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from neuspell) (1.19.5)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 35.3 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 38.5 MB/s \n",
            "\u001b[?25hCollecting jsonlines\n",
            "  Downloading jsonlines-2.0.0-py3-none-any.whl (6.3 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->neuspell) (3.7.4.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert->neuspell) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert->neuspell) (2.23.0)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.18.60-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 61.3 MB/s \n",
            "\u001b[?25hCollecting botocore<1.22.0,>=1.21.60\n",
            "  Downloading botocore-1.21.60-py3-none-any.whl (8.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.0 MB 47.0 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.60->boto3->pytorch-pretrained-bert->neuspell) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 43.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.60->boto3->pytorch-pretrained-bert->neuspell) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert->neuspell) (3.0.4)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 70.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert->neuspell) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert->neuspell) (2021.5.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->neuspell) (3.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers->neuspell) (4.8.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers->neuspell) (21.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 68.6 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 64.9 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 45.8 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers->neuspell) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers->neuspell) (3.6.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->neuspell) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->neuspell) (1.0.1)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, pyyaml, tokenizers, sacremoses, huggingface-hub, boto3, transformers, sentencepiece, pytorch-pretrained-bert, jsonlines, neuspell\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.18.60 botocore-1.21.60 huggingface-hub-0.0.19 jmespath-0.10.0 jsonlines-2.0.0 neuspell-1.0.0 pytorch-pretrained-bert-0.6.2 pyyaml-5.4.1 s3transfer-0.5.0 sacremoses-0.0.46 sentencepiece-0.1.96 tokenizers-0.10.3 transformers-4.11.3 urllib3-1.25.11\n",
            "data folder is set to `/usr/local/lib/python3.7/dist-packages/neuspell/../data` script\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "148d795530a64cfb984dbe22374686e6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "551ed8730c3a434c80aa3c40730731ea",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21eac9e4abca4ceab25fa46bdfda67b9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/426k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1040a8c5b7944547b56cc1a3cb70a32c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/neuspell/../data/checkpoints/scrnn-probwordnoise created\n",
            "Pretrained model downloading start (may take few seconds to couple of minutes based on download speed) ...\n",
            "Pretrained model download success\n",
            "loading vocab from path:/usr/local/lib/python3.7/dist-packages/neuspell/../data/checkpoints/scrnn-probwordnoise/vocab.pkl\n",
            "initializing model\n",
            "SCLSTM(\n",
            "  (lstmmodule): LSTM(294, 512, num_layers=2, batch_first=True, dropout=0.4, bidirectional=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (dense): Linear(in_features=1024, out_features=100002, bias=True)\n",
            "  (criterion): CrossEntropyLoss()\n",
            ")\n",
            "112111266\n",
            "loading pretrained weights from path:/usr/local/lib/python3.7/dist-packages/neuspell/../data/checkpoints/scrnn-probwordnoise\n",
            "Loading model params from checkpoint dir: /usr/local/lib/python3.7/dist-packages/neuspell/../data/checkpoints/scrnn-probwordnoise\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzMujc2EE017",
        "outputId": "66144ec4-d585-4c3e-ae12-4de14f2e6658"
      },
      "source": [
        "spell_corrected_student_feedback_content = checker.correct_strings([student_feedback_content])\n",
        "spell_corrected_twitter_content = checker.correct_strings([twitter_content])\n",
        "spell_corrected_research_paper_content = checker.correct_strings([research_paper_content])\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###############################################\n",
            "data size: 1\n",
            "total inference time for this data is: 7.757470 secs\n",
            "###############################################\n",
            "data size: 1\n",
            "total inference time for this data is: 10.453957 secs\n",
            "###############################################\n",
            "data size: 1\n",
            "total inference time for this data is: 8.304805 secs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2UBdLHcF1Wc",
        "outputId": "4825d391-bd8e-4599-851c-4106d45aed0c"
      },
      "source": [
        "print(\"------------------------------------------------------------------------------- \")\n",
        "print(\"----------  Student feedback content before applying spell correction  --------\")\n",
        "print(\"------------------------------------------------------------------------------- \\n\")\n",
        "print(student_feedback_content + '\\n')\n",
        "print(\"-------------------------------------------------------------------------------\")\n",
        "print(\"----------  Student feedback content after applying spell correction  ---------\")\n",
        "print(\"------------------------------------------------------------------------------- \\n\")\n",
        "print(spell_corrected_student_feedback_content[0])\n",
        "\n",
        "print(\"------------------------------------------------------------------------------- \")\n",
        "print(\"----------  Twitter content before applying spell correction  --------\")\n",
        "print(\"------------------------------------------------------------------------------- \\n\")\n",
        "print(twitter_content + '\\n')\n",
        "print(\"-------------------------------------------------------------------------------\")\n",
        "print(\"----------  Twitter content after applying spell correction  ---------\")\n",
        "print(\"------------------------------------------------------------------------------- \\n\")\n",
        "print(spell_corrected_twitter_content[0])\n",
        "\n",
        "\n",
        "print(\"------------------------------------------------------------------------------- \")\n",
        "print(\"----------  Research paper content before applying spell correction  --------\")\n",
        "print(\"------------------------------------------------------------------------------- \\n\")\n",
        "print(research_paper_content + '\\n')\n",
        "print(\"-------------------------------------------------------------------------------\")\n",
        "print(\"----------  Research paper content after applying spell correction  ---------\")\n",
        "print(\"------------------------------------------------------------------------------- \\n\")\n",
        "print(spell_corrected_research_paper_content[0])\n"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------------- \n",
            "----------  Student feedback content before applying spell correction  --------\n",
            "------------------------------------------------------------------------------- \n",
            "\n",
            "Honestly last seven lectures are good. Lectures are understandable. Lecture slides are very useful to self-study also. The given opportunity to ask questions from the lecturer is appreciative. \n",
            "\"Good :) \n",
            "<br />please do recap at class starting it&#039;s better for us.\n",
            "<br />sometimes teaching speed is very high.\n",
            "<br />\n",
            "<br />Thanks ! :)\n",
            "<br /> \"\n",
            "The lectures are good..but a bit speed.A in class working activity is a must one.So please take another hour in thursdays madame.\n",
            "\"\n",
            "<br />We can hear your voice clearly and can understand the things you teach. Presentation slides also good source to refer . lf you can do more example questions within the classroom and it will help us to understand the principles well. \n",
            "<br />\"\n",
            "Lectures was well structured and well organized. It was easy to understand. Lecture slides and labs were also well organized. \n",
            "Lectures were good. understandable. \n",
            "The lecture slides were well organized and the examples done in the class helped a lot to learn this new language and also the principles of OOP. Motivated to well. Would have been better if we discussed more about the solutions of coding exercisers.   \n",
            "I think i learned a lot from the codes you write in the board. When i compare my codes with yours i can learn about my mistakes and good coding practices that i should follow. There fore i think it would be great if we can discuss more examples in the class.\n",
            "madam explained  the oop concepts clearly with examples.lectures were interesting.we want more scenario examples and answers with explanations in future.\n",
            "I satisfy about first 7 lectures. That way of teaching is really good for coming lectures too.\n",
            "lectuers are very good. take good effort to make undersatand every student in the room. very helpfull. \n",
            "I was able to obtain a clear picture about OOP and its concepts. \n",
            "\"lecture slides, explanations were very clear.\n",
            "<br />it&#039;s very good to letting ask questions and explain again with suitable examples.\n",
            "<br />sometimes, some codes on white board were unclear at the back.\n",
            "<br />overall very good!!!\n",
            "<br />\"\n",
            "The lectures were good and clear. And they weren&#039;t too fast. Writing code was somewhat confusing because I didn&#039;t know java before. \n",
            "Actually teaching is very good and can understand easily the concepts by examples which are given in the class.it will be more helpful if provide solved questions as well!. thankyou\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "----------  Student feedback content after applying spell correction  ---------\n",
            "------------------------------------------------------------------------------- \n",
            "\n",
            "Honestly last seven lectures are good . Lecturers are understandable . Lecture slides are very useful to self -- study also . The given opportunity to ask questions from the lecturer is appreciative . \" Good : < br />please do recap at class starting it&#039;s better for us . < br sometimes teaching speed is very high . < br / < br />Thanks ) < br \" The lectures are good . but a bit speed . A in class working activity is a must one . So please take another hour in thursdays manmade . \" < br />We can hear your voice clearly and can understand the things you teach . Presentation slides also good source to refer .. if you can do more example questions within the classroom and it will help us to understand the principles well . < br \" Lecturers was well structured and well organized . It was easy to understand . Lecture slides and labs were also well organized . Lecturers were good . understandable . The lecture slides were well organized and the examples done in the class helped a lot to learn this new language and also the principles of OOP . Motivated to well . Would have been better if we discussed more about the solutions of coding exercisers . I think I learned a lot from the codes you write in the board . When i compare my codes with yours I can learn about my mistakes and good coding practices that I should follow . There for I think it would be great if we can discuss more examples in the class . madam explained the pop concepts clearly with examples.lectures were interesting.we want more scenario examples and answers with explanations in future . I satisfy about first 7 lectures . That way of teaching is really good for coming lectures too . lectures are very good . take good effort to make understand every student in the room . very helpful . I was able to obtain a clear picture about OOP and its concepts . \" lecture slides , explanations were very clear . < br />it&#039;s very good to letting ask questions and explain again with suitable examples . < br sometimes , some codes on white board were unclear at the back . < br />overall very good ! < br \" The lectures were good and clear . And the weren&#039;t too fast . Writing code was somewhat confusing because I didn&#039;t know java before . Actually teaching is very good and can understand easily the concepts by examples which are given in the class.it will be more helpful if provide solved questions as well . thank-you\n",
            "------------------------------------------------------------------------------- \n",
            "----------  Twitter content before applying spell correction  --------\n",
            "------------------------------------------------------------------------------- \n",
            "\n",
            "Reminds me of Liberal Immigration Fraudster Monsef avoiding deportation from Canada. #cdnpoli #LPC #CPCLDR��_ https://t.co/ZOZOSe1CqQ\n",
            "#immigration #integration #canada https://t.co/M5cKGyvV8F\n",
            "We want controlled immigration that contributes positively to the UK economy. Same as Australia &amp; Canada. https://t.co/99mYliuOes\n",
            "Is the new Manitoba immigration fee a head tax? https://t.co/LsG7C3vLe9\n",
            "Canada immigration profit influence modernistic delhi yet abhinav: XKofy https://t.co/becgusY2i6\n",
            "Canada Immigration Minister to ���Substantially Increase  Immigration Numbers https://t.co/nEFw30MRaa https://t.co/cyI867PZRV\n",
            "M��me les #USA=pays d'immigration par excellence CONTR��LE RIGOUREUSEMENT l'immigration et acc��s �� la #GreenCARD!��_ https://t.co/IHpVhW2BaG\n",
            "@Shawhelp what changes should be made to Canada's immigration laws due to the influx of immigration and violence?\n",
            "L��immigration irr��guli��re au Canada d��cortiqu��e en 5 questions https://t.co/f4utO5A7ZF\n",
            "L'immigration irr��guli��re au Canada d��cortiqu��e en 5 questions - https://t.co/UiBsEZOqas https://t.co/j77dEvjoiX https://t.co/XXDeIG7Dbu\n",
            "Will Media ask the Liberals if they actually have a solid plan for Canada _��_�_?? From my view -- immigration out of C��_ https://t.co/YAgwmZ8ECp\n",
            "Dan Murray of��Immigration Watch Canada is xenophobic racist fear-mongering liar #racism #canada #cdnpoli #hatecrime��_ https://t.co/kwZ3csvYxM\n",
            "Le Canada lance une vaste campagne d'immigration pour faire face �� son besoin de main d'��uvre https://t.co/kXdfMGTZzN\n",
            "L��#immigration irr��guli��re au #Canada d��cortiqu��e en 5��questions https://t.co/s3hu1OKKIG\n",
            "@Canadidly I've read the Immigration laws of Canada much stricter than the US\n",
            "Canada Immigration Website Traffic Surges And Crashes In Wake Of Trump #fasttraffic,#sitetraffic,#website,#traffic https://t.co/zRlJ26jnkC\n",
            "Mr Know-all of Canada Immigration https://t.co/wTQK4QDiKI\n",
            "Move to Canada @LadyMadonna___ Oh, immigration rules, you can't... https://t.co/5LIEVHO7A4\n",
            "#OnThisDay Annette Toft becomes Canada's 2 millionth immigrant since 1945. Do you know your family's immigration st��_ https://t.co/UvRuw8eR1b\n",
            ".@TheEconomist profiles Canada's open immigration policies &amp; how they contribute to our economic success:��_ https://t.co/4K84EE8Y63\n",
            "Hundreds may lose Canadian citizenship, resident status because of one corrupt immigration consultant https://t.co/x2IfO0EXI2\n",
            "Immigration for canada without india: an compassionate handle: deyFy\n",
            "\"#Jamaican #immigrants #Canada\n",
            "\n",
            "https://t.co/vcmfYGadR5\n",
            "\n",
            "#statistics #immigration\"\n",
            "Mexican visa lift expected to cost Canada $262M over a decade https://t.co/9i72fRhtij\n",
            "Are people still moving to #Canada ??? Oh that's right, they have real immigration laws and it's��_ https://t.co/0C5OBfmxLG\n",
            "Here are more details on the Richmond, B.C. Immigration Consultant Sunny Wang who was sentenced to 7 years in... https://t.co/YXH5W53srO\n",
            "I added a video to a @YouTube playlist https://t.co/CnEyWN40x3 Funny Talking of Haryanavi Jat with Canada Immigration Girl Agent\n",
            "Mexicans Can Now Travel Visa-Free To Canada https://t.co/Ec3XHORO2s https://t.co/RQRr5nebcG\n",
            "L��immigration irr��guli��re au Canada d��cortiqu��e en 5��questions https://t.co/DkpuKyWmaK\n",
            "@SweetnessShawnB Hes the POS that ramped up immigration for Canada, among other globalist policies.\n",
            "Canada lifted visa requirements to Mexico as of Dec 1, 2016. Thoughts? #visa #immigration\n",
            "@HuffingtonPost people Keep praising Canada and Canada has way stricter immigration laws then us they willl boot your liberal American ass\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "----------  Twitter content after applying spell correction  ---------\n",
            "------------------------------------------------------------------------------- \n",
            "\n",
            "Reminds me of Liberal Immigration Fraudster Monsef avoiding deportation from Canada .# cdnpoli # LPC # CPCLDR and � _ https://t.co/ZOZOSe1CqQ # immigration # integration # canada https://t.co/M5cKGyvV8F We want controlled immigration that contributes positively to the UK economy . Same as Australia & amp ; Canada . https://t.co/99mYliuOes Is the new Manitoba immigration fee a head tax ? https://t.co/LsG7C3vLe9 Canada immigration profit influence modernistic delhi yet abhinav : XKofy https://t.co/becgusY2i6 Canada Immigration Minister to and and and Substantially Increase Immigration Numbers https://t.co/nEFw30MRaa https://t.co/cyI867PZRV M and and me les # USA = pays d'immigration par excellence CONTR and � LE RIGOUREUSEMENT l'immigration et acc and and s and and la # GreenCARD ! and � _ https://t.co/IHpVhW2BaG @Shawhelp what changes should be made to Canada 's immigration laws due to the influx of immigration and violence ? L � and immigration irr � and guli and � re au Canada d � and cortiqu � and e en 5 questions https://t.co/f4utO5A7ZF L'immigration irr � and guli and � re au Canada d � and cortiqu � and e en 5 questions -- https://t.co/UiBsEZOqas https://t.co/j77dEvjoiX https://t.co/XXDeIG7Dbu Will Media ask the Liberals if they actually have a solid plan for Canada _ and � _ � _ From my view -- immigration out of C and � _ https://t.co/YAgwmZ8ECp Dan Murray of and and Immigration Watch Canada is xenophobic racist fear -- mongering liar # racism # canada # cdnpoli # hatecrime and � _ https://t.co/kwZ3csvYxM Le Canada lance use vast campagne d'immigration pour faire face and and son besoin de main d � and uvre https://t.co/kXdfMGTZzN L � and #immigration irr � � guli � � re au # Canada d � and cortiqu � and e en 5 and and questions https://t.co/s3hu1OKKIG @Canadidly I 've read the Immigration laws of Canada much stricter than the US Canada Immigration Website Traffic Surges And Crashes In Wake Of Trump # fasttraffic,#sitetraffic,#website,#traffic https://t.co/zRlJ26jnkC Mr Know -- all of Canada Immigration https://t.co/wTQK4QDiKI Move to Canada @LadyMadonna _ Oh , immigration rules , you is not ... https://t.co/5LIEVHO7A4 # OnThisDay Annette Toft becomes Canada 's 2 millionth immigrant since 1945 . Do you know your family 's immigration set and � _ https://t.co/UvRuw8eR1b .@TheEconomist profiles Canada 's open immigration policies & amp ; how they contribute to our economic success : and and _ https://t.co/4K84EE8Y63 Hundreds may lose Canadian citizenship , resident status because of one corrupt immigration consultant https://t.co/x2IfO0EXI2 Immigration for canada without india : an compassionate handle : deyFy \" Jamaican # immigrants # Canada https://t.co/vcmfYGadR5 # statistics # immigration \" Mexican visa lift expected to cost Canada $ 262 M over a decade https://t.co/9i72fRhtij Are people still moving to # Canada ? Oh that 's right , they have real immigration laws and it 's and and _ https://t.co/0C5OBfmxLG Here are more details on the Richmond , B.C. Immigration Consultant Sunny Wang who was sentenced to 7 years in ... https://t.co/YXH5W53srO I added a video to a YouTube playlist https://t.co/CnEyWN40x3 Funny Talking of Haryanavi Jay with Canada Immigration Girl Agent Mexicans Can Now Travel Visa - Free To Canada https://t.co/Ec3XHORO2s https://t.co/RQRr5nebcG L and and immigration irr � and guli and � re au Canada d � and cortiqu � and e en 5 and and questions https://t.co/DkpuKyWmaK @SweetnessShawnB He 's the POS that ramped up immigration for Canada , among other globalist policies . Canada lifted visa requirements to Mexico as of Dec 1 , 2016 . Thoughts # visa # immigration @HuffingtonPost people Keep praising Canada and Canada has way stricter immigration laws then us they will boot your liberal American as\n",
            "------------------------------------------------------------------------------- \n",
            "----------  Research paper content before applying spell correction  --------\n",
            "------------------------------------------------------------------------------- \n",
            "\n",
            "Neural network models have shown their promising opportunities for multi-task\n",
            "learning, which focus on learning the shared layers to extract the common and\n",
            "task-invariant features. However, in most existing approaches, the extracted shared\n",
            "features are prone to be contaminated by task-specific features or the noise brought\n",
            "by other tasks. In this paper, we propose an adversarial multi-task learning framework,\n",
            "alleviating the shared and private latent feature spaces from interfering with\n",
            "each other. We conduct extensive experiments on 16 different text classification\n",
            "tasks, which demonstrates the benefits of our approach. Besides, we show that the\n",
            "shared knowledge learned by our proposed model can be regarded as off-the-shelf\n",
            "knowledge and easily transferred to new tasks.\n",
            "\n",
            "Multi-task learning is an effective approach to improve the performance of a single task with\n",
            "the help of other related tasks. Recently, neural-based models for multi-task learning have become\n",
            "very popular, ranging from computer vision (Misra et al., 2016; Zhang et al., 2014) to natural\n",
            "language processing (Collobert andWeston, 2008; Luong et al., 2015), since they provide a convenient\n",
            "way of combining information from multiple tasks.\n",
            "However, most existing work on multi-task learning (Liu et al., 2016c,b) attempts to divide the\n",
            "features of different tasks into private and shared spaces, merely based on whether parameters of some components should be shared. As shown in Figure 1-(a), the general shared-private model introduces\n",
            "two feature spaces for any task: one is used to store task-dependent features, the other is\n",
            "used to capture shared features. The major limitation of this framework is that the shared feature\n",
            "space could contain some unnecessary task-specific features, while some sharable features\n",
            "could also be mixed in private space, suffering from feature redundancy.\n",
            "Taking the following two sentences as examples, which are extracted from two different sentiment\n",
            "classification tasks: Movie reviews and Baby products reviews.\n",
            "The infantile cart is simple and easy to use. This kind of humour is infantile and boring.\n",
            "The word �infantile� indicates negative sentiment in Movie task while it is neutral in Baby task.\n",
            "However, the general shared-private model could place the task-specific word �infantile� in a\n",
            "shared space, leaving potential hazards for other tasks. Additionally, the capacity of shared space\n",
            "could also be wasted by some unnecessary features.\n",
            "To address this problem, in this paper we propose an adversarial multi-task framework, in\n",
            "which the shared and private feature spaces are in herently disjoint by introducing orthogonality constraints.Specifically, we design a generic shared private learning framework to model the text sequence.\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "----------  Research paper content after applying spell correction  ---------\n",
            "------------------------------------------------------------------------------- \n",
            "\n",
            "Natural network models have shown their promising opportunities for multi -- task learning , which focus on learning the shared layers to extract the common and task -- vibrant features . However , in most existing approaches , the extracted shared features are prone to be contaminated by task -- specific features or the noise brought by other tasks . In this paper , we propose an adversaries multi -- task learning framework , alleviating the shared and private latent feature spaces from interfering with each other . We conduct extensive experiments on 16 different text classification tasks , which demonstrates the benefits of our approach . Besides , we show that the shared knowledge learned by our proposed model can be regarded as off -- the -- shelf knowledge and easily transferred to new tasks . Multi -- task learning is an effective approach to improve the performance of a single task with the help of other related tasks . Recently , neural -- based models for multi -- task learning have become very popular , ranging from computer vision ( Misra et al , 2016 ; Zhang et al , 2014 ) to natural language processing ( Collobert andWeston , 2008 ; Luong et al , 2015 , since they provide a convenient way of combining information from multiple tasks . However , most existing work on multi -- task learning ( Liu et al , 2016c , b ) attempts to divide the features of different tasks into private and shared spaces , merely based on whether parameters of some components should be shared . As shown in Figure 1-(a , the general shared -- private model introduces to feature spaces for any task : one is used to store task -- dependent features , the other is used to capture shared features . The major limitation of this framework is that the shared feature space could contain some unnecessary task -- specific features , while some sharable features could also be mixed in private space , suffering from feature redundancy . Taking the following two sentences as examples , which are extracted from two different sentiment classification tasks : Movie reviews and Baby products reviews . The infantile card is simple and easy to use . This kind of humour is infantile and boring . The word and infantile and indicates negative sentiment in Movie task while it is neutral in Baby task . However , the general shared -- private model could place the task -- specific word and infantile and in a shared space , leaving potential hazards for other tasks . Additionally , the capacity of shared space could also be wasted by some unnecessary features . To address this problem , in this paper we propose an adversaries multi -- task framework , in which the shared and private feature spaces are in entirely dishonest by introducing orthogonality constraints . Specifically , we design a generic shared private learning framework to model the text sequence .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwuC3xLpXuqv"
      },
      "source": [
        "preprocessed_text = [preprocessText(question) for question in tokenized_student_feedback_content]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWNiA_dgL0uL"
      },
      "source": [
        "## **Isolated word correction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENlrEWAh1jF3",
        "outputId": "022927d7-2545-4f31-8433-cba6b3c26cc1"
      },
      "source": [
        "import re\n",
        "import string\n",
        "from nltk.metrics.distance  import edit_distance\n",
        "nltk.download('words')\n",
        "from nltk.corpus import words\n",
        "correct_words = words.words()\n",
        "\n",
        "def correctSpellingInText(text):\n",
        "\n",
        "  preprocessedWords = []\n",
        "\n",
        "  for word in text:\n",
        "    #remove HTML tags\n",
        "    html_tags = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
        "    cleantext = re.sub(html_tags, '', word)\n",
        "\n",
        "    #replace punctuation marks by empty string\n",
        "    regular_punct = list(string.punctuation)\n",
        "    for punc in regular_punct:\n",
        "          if punc in cleantext:\n",
        "              cleantext = cleantext.replace(punc, '')\n",
        "\n",
        "    preprocessedWords.append(cleantext)\n",
        "\n",
        "  \n",
        "  print(\"preprocessedWords\", preprocessedWords)\n",
        "  print(\"cleantext\",cleantext)\n",
        "\n",
        "  spellCorrectedText = \"\"\n",
        "\n",
        "  for word in preprocessedWords:\n",
        "    if(len(word)>1 and not(word.isnumeric())):\n",
        "      temp = [(edit_distance(word, w),w) for w in correct_words if w[0]==word[0]]\n",
        "      print(word + \" -> \" + sorted(temp, key = lambda val:val[0])[0][1])\n",
        "      spellCorrectedText = spellCorrectedText + \" \" + sorted(temp, key = lambda val:val[0])[0][1]\n",
        "    else:\n",
        "      spellCorrectedText = spellCorrectedText + \" \" + word\n",
        "\n",
        "  print(spellCorrectedText)\n",
        "\n",
        "  return spellCorrectedText\n",
        "\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFFss_uy7hpp",
        "outputId": "231b572a-98a0-4e2b-deba-4082ffc9b7d0"
      },
      "source": [
        "second_spell_corrected_student_feedback_content = correctSpellingInText(tokenized_student_feedback_content)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preprocessedWords ['Honestly', 'last', 'seven', 'lectures', 'are', 'good', '', 'Lectures', 'are', 'understandable', '', 'Lecture', 'slides', 'are', 'very', 'useful', 'to', 'selfstudy', 'also', '', 'The', 'given', 'opportunity', 'to', 'ask', 'questions', 'from', 'the', 'lecturer', 'is', 'appreciative', '', '', 'Good', '', '', '', 'br', '', '', 'please', 'do', 'recap', 'at', 'class', 'starting', 'it', '', '', '039', '', 's', 'better', 'for', 'us', '', '', 'br', '', '', 'sometimes', 'teaching', 'speed', 'is', 'very', 'high', '', '', 'br', '', '', '', 'br', '', '', 'Thanks', '', '', '', '', 'br', '', '', '', 'The', 'lectures', 'are', 'goodbut', 'a', 'bit', 'speedA', 'in', 'class', 'working', 'activity', 'is', 'a', 'must', 'oneSo', 'please', 'take', 'another', 'hour', 'in', 'thursdays', 'madame', '', '', 'br', '', '', 'We', 'can', 'hear', 'your', 'voice', 'clearly', 'and', 'can', 'understand', 'the', 'things', 'you', 'teach', '', 'Presentation', 'slides', 'also', 'good', 'source', 'to', 'refer', '', 'lf', 'you', 'can', 'do', 'more', 'example', 'questions', 'within', 'the', 'classroom', 'and', 'it', 'will', 'help', 'us', 'to', 'understand', 'the', 'principles', 'well', '', '', 'br', '', '', '', 'Lectures', 'was', 'well', 'structured', 'and', 'well', 'organized', '', 'It', 'was', 'easy', 'to', 'understand', '', 'Lecture', 'slides', 'and', 'labs', 'were', 'also', 'well', 'organized', '', 'Lectures', 'were', 'good', '', 'understandable', '', 'The', 'lecture', 'slides', 'were', 'well', 'organized', 'and', 'the', 'examples', 'done', 'in', 'the', 'class', 'helped', 'a', 'lot', 'to', 'learn', 'this', 'new', 'language', 'and', 'also', 'the', 'principles', 'of', 'OOP', '', 'Motivated', 'to', 'well', '', 'Would', 'have', 'been', 'better', 'if', 'we', 'discussed', 'more', 'about', 'the', 'solutions', 'of', 'coding', 'exercisers', '', 'I', 'think', 'i', 'learned', 'a', 'lot', 'from', 'the', 'codes', 'you', 'write', 'in', 'the', 'board', '', 'When', 'i', 'compare', 'my', 'codes', 'with', 'yours', 'i', 'can', 'learn', 'about', 'my', 'mistakes', 'and', 'good', 'coding', 'practices', 'that', 'i', 'should', 'follow', '', 'There', 'fore', 'i', 'think', 'it', 'would', 'be', 'great', 'if', 'we', 'can', 'discuss', 'more', 'examples', 'in', 'the', 'class', '', 'madam', 'explained', 'the', 'oop', 'concepts', 'clearly', 'with', 'exampleslectures', 'were', 'interestingwe', 'want', 'more', 'scenario', 'examples', 'and', 'answers', 'with', 'explanations', 'in', 'future', '', 'I', 'satisfy', 'about', 'first', '7', 'lectures', '', 'That', 'way', 'of', 'teaching', 'is', 'really', 'good', 'for', 'coming', 'lectures', 'too', '', 'lectuers', 'are', 'very', 'good', '', 'take', 'good', 'effort', 'to', 'make', 'undersatand', 'every', 'student', 'in', 'the', 'room', '', 'very', 'helpfull', '', 'I', 'was', 'able', 'to', 'obtain', 'a', 'clear', 'picture', 'about', 'OOP', 'and', 'its', 'concepts', '', '', 'lecture', 'slides', '', 'explanations', 'were', 'very', 'clear', '', '', 'br', '', '', 'it', '', '', '039', '', 's', 'very', 'good', 'to', 'letting', 'ask', 'questions', 'and', 'explain', 'again', 'with', 'suitable', 'examples', '', '', 'br', '', '', 'sometimes', '', 'some', 'codes', 'on', 'white', 'board', 'were', 'unclear', 'at', 'the', 'back', '', '', 'br', '', '', 'overall', 'very', 'good', '', '', '', '', 'br', '', '', '', 'The', 'lectures', 'were', 'good', 'and', 'clear', '', 'And', 'they', 'weren', '', '', '039', '', 't', 'too', 'fast', '', 'Writing', 'code', 'was', 'somewhat', 'confusing', 'because', 'I', 'didn', '', '', '039', '', 't', 'know', 'java', 'before', '', 'Actually', 'teaching', 'is', 'very', 'good', 'and', 'can', 'understand', 'easily', 'the', 'concepts', 'by', 'examples', 'which', 'are', 'given', 'in', 'the', 'classit', 'will', 'be', 'more', 'helpful', 'if', 'provide', 'solved', 'questions', 'as', 'well', '', '', 'thankyou']\n",
            "cleantext thankyou\n",
            "Honestly -> Hester\n",
            "last -> last\n",
            "seven -> seven\n",
            "lectures -> lecture\n",
            "are -> are\n",
            "good -> good\n",
            "Lectures -> Leonurus\n",
            "are -> are\n",
            "understandable -> understandable\n",
            "Lecture -> Lactuca\n",
            "slides -> sides\n",
            "are -> are\n",
            "very -> very\n",
            "useful -> useful\n",
            "to -> to\n",
            "selfstudy -> saleslady\n",
            "also -> also\n",
            "The -> The\n",
            "given -> given\n",
            "opportunity -> opportunity\n",
            "to -> to\n",
            "ask -> ask\n",
            "questions -> question\n",
            "from -> from\n",
            "the -> the\n",
            "lecturer -> lecturer\n",
            "is -> is\n",
            "appreciative -> appreciative\n",
            "Good -> God\n",
            "br -> b\n",
            "please -> please\n",
            "do -> do\n",
            "recap -> recap\n",
            "at -> at\n",
            "class -> class\n",
            "starting -> starting\n",
            "it -> it\n",
            "better -> better\n",
            "for -> for\n",
            "us -> us\n",
            "br -> b\n",
            "sometimes -> sometimes\n",
            "teaching -> teaching\n",
            "speed -> speed\n",
            "is -> is\n",
            "very -> very\n",
            "high -> high\n",
            "br -> b\n",
            "br -> b\n",
            "Thanks -> Thais\n",
            "br -> b\n",
            "The -> The\n",
            "lectures -> lecture\n",
            "are -> are\n",
            "goodbut -> goldbug\n",
            "bit -> bit\n",
            "speedA -> speed\n",
            "in -> in\n",
            "class -> class\n",
            "working -> working\n",
            "activity -> activity\n",
            "is -> is\n",
            "must -> must\n",
            "oneSo -> ohelo\n",
            "please -> please\n",
            "take -> take\n",
            "another -> another\n",
            "hour -> hour\n",
            "in -> in\n",
            "thursdays -> thenadays\n",
            "madame -> madame\n",
            "br -> b\n",
            "We -> W\n",
            "can -> can\n",
            "hear -> hear\n",
            "your -> your\n",
            "voice -> voice\n",
            "clearly -> clearly\n",
            "and -> and\n",
            "can -> can\n",
            "understand -> understand\n",
            "the -> the\n",
            "things -> thing\n",
            "you -> you\n",
            "teach -> teach\n",
            "Presentation -> Predentata\n",
            "slides -> sides\n",
            "also -> also\n",
            "good -> good\n",
            "source -> source\n",
            "to -> to\n",
            "refer -> refer\n",
            "lf -> l\n",
            "you -> you\n",
            "can -> can\n",
            "do -> do\n",
            "more -> more\n",
            "example -> example\n",
            "questions -> question\n",
            "within -> within\n",
            "the -> the\n",
            "classroom -> classroom\n",
            "and -> and\n",
            "it -> it\n",
            "will -> will\n",
            "help -> help\n",
            "us -> us\n",
            "to -> to\n",
            "understand -> understand\n",
            "the -> the\n",
            "principles -> principes\n",
            "well -> well\n",
            "br -> b\n",
            "Lectures -> Leonurus\n",
            "was -> was\n",
            "well -> well\n",
            "structured -> structured\n",
            "and -> and\n",
            "well -> well\n",
            "organized -> organized\n",
            "It -> I\n",
            "was -> was\n",
            "easy -> easy\n",
            "to -> to\n",
            "understand -> understand\n",
            "Lecture -> Lactuca\n",
            "slides -> sides\n",
            "and -> and\n",
            "labs -> lab\n",
            "were -> were\n",
            "also -> also\n",
            "well -> well\n",
            "organized -> organized\n",
            "Lectures -> Leonurus\n",
            "were -> were\n",
            "good -> good\n",
            "understandable -> understandable\n",
            "The -> The\n",
            "lecture -> lecture\n",
            "slides -> sides\n",
            "were -> were\n",
            "well -> well\n",
            "organized -> organized\n",
            "and -> and\n",
            "the -> the\n",
            "examples -> example\n",
            "done -> done\n",
            "in -> in\n",
            "the -> the\n",
            "class -> class\n",
            "helped -> helmed\n",
            "lot -> lot\n",
            "to -> to\n",
            "learn -> learn\n",
            "this -> this\n",
            "new -> new\n",
            "language -> language\n",
            "and -> and\n",
            "also -> also\n",
            "the -> the\n",
            "principles -> principes\n",
            "of -> of\n",
            "OOP -> O\n",
            "Motivated -> Molidae\n",
            "to -> to\n",
            "well -> well\n",
            "Would -> Wolf\n",
            "have -> have\n",
            "been -> been\n",
            "better -> better\n",
            "if -> if\n",
            "we -> we\n",
            "discussed -> discusser\n",
            "more -> more\n",
            "about -> about\n",
            "the -> the\n",
            "solutions -> solution\n",
            "of -> of\n",
            "coding -> codding\n",
            "exercisers -> exerciser\n",
            "think -> think\n",
            "learned -> learned\n",
            "lot -> lot\n",
            "from -> from\n",
            "the -> the\n",
            "codes -> code\n",
            "you -> you\n",
            "write -> write\n",
            "in -> in\n",
            "the -> the\n",
            "board -> board\n",
            "When -> Wren\n",
            "compare -> compare\n",
            "my -> my\n",
            "codes -> code\n",
            "with -> with\n",
            "yours -> yours\n",
            "can -> can\n",
            "learn -> learn\n",
            "about -> about\n",
            "my -> my\n",
            "mistakes -> mistake\n",
            "and -> and\n",
            "good -> good\n",
            "coding -> codding\n",
            "practices -> practice\n",
            "that -> that\n",
            "should -> should\n",
            "follow -> follow\n",
            "There -> Teri\n",
            "fore -> fore\n",
            "think -> think\n",
            "it -> it\n",
            "would -> would\n",
            "be -> be\n",
            "great -> great\n",
            "if -> if\n",
            "we -> we\n",
            "can -> can\n",
            "discuss -> discuss\n",
            "more -> more\n",
            "examples -> example\n",
            "in -> in\n",
            "the -> the\n",
            "class -> class\n",
            "madam -> madam\n",
            "explained -> explainer\n",
            "the -> the\n",
            "oop -> o\n",
            "concepts -> concept\n",
            "clearly -> clearly\n",
            "with -> with\n",
            "exampleslectures -> exampleless\n",
            "were -> were\n",
            "interestingwe -> interesting\n",
            "want -> want\n",
            "more -> more\n",
            "scenario -> scenario\n",
            "examples -> example\n",
            "and -> and\n",
            "answers -> answer\n",
            "with -> with\n",
            "explanations -> explanation\n",
            "in -> in\n",
            "future -> future\n",
            "satisfy -> satisfy\n",
            "about -> about\n",
            "first -> first\n",
            "lectures -> lecture\n",
            "That -> Tat\n",
            "way -> way\n",
            "of -> of\n",
            "teaching -> teaching\n",
            "is -> is\n",
            "really -> really\n",
            "good -> good\n",
            "for -> for\n",
            "coming -> coming\n",
            "lectures -> lecture\n",
            "too -> too\n",
            "lectuers -> lectern\n",
            "are -> are\n",
            "very -> very\n",
            "good -> good\n",
            "take -> take\n",
            "good -> good\n",
            "effort -> effort\n",
            "to -> to\n",
            "make -> make\n",
            "undersatand -> understand\n",
            "every -> every\n",
            "student -> student\n",
            "in -> in\n",
            "the -> the\n",
            "room -> room\n",
            "very -> very\n",
            "helpfull -> helpful\n",
            "was -> was\n",
            "able -> able\n",
            "to -> to\n",
            "obtain -> obtain\n",
            "clear -> clear\n",
            "picture -> picture\n",
            "about -> about\n",
            "OOP -> O\n",
            "and -> and\n",
            "its -> its\n",
            "concepts -> concept\n",
            "lecture -> lecture\n",
            "slides -> sides\n",
            "explanations -> explanation\n",
            "were -> were\n",
            "very -> very\n",
            "clear -> clear\n",
            "br -> b\n",
            "it -> it\n",
            "very -> very\n",
            "good -> good\n",
            "to -> to\n",
            "letting -> lasting\n",
            "ask -> ask\n",
            "questions -> question\n",
            "and -> and\n",
            "explain -> explain\n",
            "again -> again\n",
            "with -> with\n",
            "suitable -> suitable\n",
            "examples -> example\n",
            "br -> b\n",
            "sometimes -> sometimes\n",
            "some -> some\n",
            "codes -> code\n",
            "on -> on\n",
            "white -> white\n",
            "board -> board\n",
            "were -> were\n",
            "unclear -> unclear\n",
            "at -> at\n",
            "the -> the\n",
            "back -> back\n",
            "br -> b\n",
            "overall -> overall\n",
            "very -> very\n",
            "good -> good\n",
            "br -> b\n",
            "The -> The\n",
            "lectures -> lecture\n",
            "were -> were\n",
            "good -> good\n",
            "and -> and\n",
            "clear -> clear\n",
            "And -> Ana\n",
            "they -> they\n",
            "weren -> ween\n",
            "too -> too\n",
            "fast -> fast\n",
            "Writing -> Waibling\n",
            "code -> code\n",
            "was -> was\n",
            "somewhat -> somewhat\n",
            "confusing -> conducing\n",
            "because -> because\n",
            "didn -> dian\n",
            "know -> know\n",
            "java -> jama\n",
            "before -> before\n",
            "Actually -> Achuas\n",
            "teaching -> teaching\n",
            "is -> is\n",
            "very -> very\n",
            "good -> good\n",
            "and -> and\n",
            "can -> can\n",
            "understand -> understand\n",
            "easily -> easily\n",
            "the -> the\n",
            "concepts -> concept\n",
            "by -> by\n",
            "examples -> example\n",
            "which -> which\n",
            "are -> are\n",
            "given -> given\n",
            "in -> in\n",
            "the -> the\n",
            "classit -> classic\n",
            "will -> will\n",
            "be -> be\n",
            "more -> more\n",
            "helpful -> helpful\n",
            "if -> if\n",
            "provide -> provide\n",
            "solved -> solve\n",
            "questions -> question\n",
            "as -> as\n",
            "well -> well\n",
            "thankyou -> thanedom\n",
            " Hester last seven lecture are good  Leonurus are understandable  Lactuca sides are very useful to saleslady also  The given opportunity to ask question from the lecturer is appreciative   God    b   please do recap at class starting it   039  s better for us   b   sometimes teaching speed is very high   b    b   Thais     b    The lecture are goldbug a bit speed in class working activity is a must ohelo please take another hour in thenadays madame   b   W can hear your voice clearly and can understand the thing you teach  Predentata sides also good source to refer  l you can do more example question within the classroom and it will help us to understand the principes well   b    Leonurus was well structured and well organized  I was easy to understand  Lactuca sides and lab were also well organized  Leonurus were good  understandable  The lecture sides were well organized and the example done in the class helmed a lot to learn this new language and also the principes of O  Molidae to well  Wolf have been better if we discusser more about the solution of codding exerciser  I think i learned a lot from the code you write in the board  Wren i compare my code with yours i can learn about my mistake and good codding practice that i should follow  Teri fore i think it would be great if we can discuss more example in the class  madam explainer the o concept clearly with exampleless were interesting want more scenario example and answer with explanation in future  I satisfy about first 7 lecture  Tat way of teaching is really good for coming lecture too  lectern are very good  take good effort to make understand every student in the room  very helpful  I was able to obtain a clear picture about O and its concept   lecture sides  explanation were very clear   b   it   039  s very good to lasting ask question and explain again with suitable example   b   sometimes  some code on white board were unclear at the back   b   overall very good     b    The lecture were good and clear  Ana they ween   039  t too fast  Waibling code was somewhat conducing because I dian   039  t know jama before  Achuas teaching is very good and can understand easily the concept by example which are given in the classic will be more helpful if provide solve question as well   thanedom\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJEupR4N_-pI",
        "outputId": "97b495ab-20d1-43ca-a08e-30778961e268"
      },
      "source": [
        "print(\"------------------------------------------------------------------------------- \")\n",
        "print(\"----------  Student feedback content before applying spell correction  --------\")\n",
        "print(\"------------------------------------------------------------------------------- \\n\")\n",
        "print(student_feedback_content + '\\n')\n",
        "print(\"-------------------------------------------------------------------------------\")\n",
        "print(\"----------  Student feedback content after applying spell correction  ---------\")\n",
        "print(\"------------------------------------------------------------------------------- \\n\")\n",
        "print(second_spell_corrected_student_feedback_content)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------------- \n",
            "----------  Student feedback content before applying spell correction  --------\n",
            "------------------------------------------------------------------------------- \n",
            "\n",
            "Honestly last seven lectures are good. Lectures are understandable. Lecture slides are very useful to self-study also. The given opportunity to ask questions from the lecturer is appreciative. \n",
            "\"Good :) \n",
            "<br />please do recap at class starting it&#039;s better for us.\n",
            "<br />sometimes teaching speed is very high.\n",
            "<br />\n",
            "<br />Thanks ! :)\n",
            "<br /> \"\n",
            "The lectures are good..but a bit speed.A in class working activity is a must one.So please take another hour in thursdays madame.\n",
            "\"\n",
            "<br />We can hear your voice clearly and can understand the things you teach. Presentation slides also good source to refer . lf you can do more example questions within the classroom and it will help us to understand the principles well. \n",
            "<br />\"\n",
            "Lectures was well structured and well organized. It was easy to understand. Lecture slides and labs were also well organized. \n",
            "Lectures were good. understandable. \n",
            "The lecture slides were well organized and the examples done in the class helped a lot to learn this new language and also the principles of OOP. Motivated to well. Would have been better if we discussed more about the solutions of coding exercisers.   \n",
            "I think i learned a lot from the codes you write in the board. When i compare my codes with yours i can learn about my mistakes and good coding practices that i should follow. There fore i think it would be great if we can discuss more examples in the class.\n",
            "madam explained  the oop concepts clearly with examples.lectures were interesting.we want more scenario examples and answers with explanations in future.\n",
            "I satisfy about first 7 lectures. That way of teaching is really good for coming lectures too.\n",
            "lectuers are very good. take good effort to make undersatand every student in the room. very helpfull. \n",
            "I was able to obtain a clear picture about OOP and its concepts. \n",
            "\"lecture slides, explanations were very clear.\n",
            "<br />it&#039;s very good to letting ask questions and explain again with suitable examples.\n",
            "<br />sometimes, some codes on white board were unclear at the back.\n",
            "<br />overall very good!!!\n",
            "<br />\"\n",
            "The lectures were good and clear. And they weren&#039;t too fast. Writing code was somewhat confusing because I didn&#039;t know java before. \n",
            "Actually teaching is very good and can understand easily the concepts by examples which are given in the class.it will be more helpful if provide solved questions as well!. thankyou\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "----------  Student feedback content after applying spell correction  ---------\n",
            "------------------------------------------------------------------------------- \n",
            "\n",
            " Hester last seven lecture are good  Leonurus are understandable  Lactuca sides are very useful to saleslady also  The given opportunity to ask question from the lecturer is appreciative   God    b   please do recap at class starting it   039  s better for us   b   sometimes teaching speed is very high   b    b   Thais     b    The lecture are goldbug a bit speed in class working activity is a must ohelo please take another hour in thenadays madame   b   W can hear your voice clearly and can understand the thing you teach  Predentata sides also good source to refer  l you can do more example question within the classroom and it will help us to understand the principes well   b    Leonurus was well structured and well organized  I was easy to understand  Lactuca sides and lab were also well organized  Leonurus were good  understandable  The lecture sides were well organized and the example done in the class helmed a lot to learn this new language and also the principes of O  Molidae to well  Wolf have been better if we discusser more about the solution of codding exerciser  I think i learned a lot from the code you write in the board  Wren i compare my code with yours i can learn about my mistake and good codding practice that i should follow  Teri fore i think it would be great if we can discuss more example in the class  madam explainer the o concept clearly with exampleless were interesting want more scenario example and answer with explanation in future  I satisfy about first 7 lecture  Tat way of teaching is really good for coming lecture too  lectern are very good  take good effort to make understand every student in the room  very helpful  I was able to obtain a clear picture about O and its concept   lecture sides  explanation were very clear   b   it   039  s very good to lasting ask question and explain again with suitable example   b   sometimes  some code on white board were unclear at the back   b   overall very good     b    The lecture were good and clear  Ana they ween   039  t too fast  Waibling code was somewhat conducing because I dian   039  t know jama before  Achuas teaching is very good and can understand easily the concept by example which are given in the classic will be more helpful if provide solve question as well   thanedom\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvMgZ2zu8Yyl"
      },
      "source": [
        "## **Lemmatization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQ-AyRjV4gdh",
        "outputId": "2d031297-20f5-464f-99dd-0094891294da"
      },
      "source": [
        "#required libraries for Lemmatization\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "# Create WordNetLemmatizer object\n",
        "wordLemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatizeText(text):\n",
        "    tokenized_words = word_tokenize(text)\n",
        "    lemmatized_word = [wordLemmatizer.lemmatize(word) for word in tokenized_words]\n",
        "    return \" \".join(lemmatized_word)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqNGQp8z419N"
      },
      "source": [
        "lemmatized_student_feedback = lemmatizeText(student_feedback_content) \n",
        "lemmatized_twitter_content = lemmatizeText(twitter_content)\n",
        "lemmatized_research_paper_content = lemmatizeText(research_paper_content)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kO_XnASkL4sC",
        "outputId": "036cf18c-0aad-4180-cae5-0409f40841ed"
      },
      "source": [
        "print(\"------------------------------------------------------------------------------- \")\n",
        "print(\"---------------   Twitter content before lemmatization  -----------------------\")\n",
        "print(\"------------------------------------------------------------------------------- \\n\")\n",
        "print(twitter_content + '\\n')\n",
        "print(\"-------------------------------------------------------------------------------\")\n",
        "print(\"----------------  Twitter content after lemmatization  ------------------------\")\n",
        "print(\"------------------------------------------------------------------------------- \\n\")\n",
        "print(lemmatized_twitter_content)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------------- \n",
            "---------------   Twitter content before lemmatization  -----------------------\n",
            "------------------------------------------------------------------------------- \n",
            "\n",
            "Reminds me of Liberal Immigration Fraudster Monsef avoiding deportation from Canada. #cdnpoli #LPC #CPCLDR��_ https://t.co/ZOZOSe1CqQ\n",
            "#immigration #integration #canada https://t.co/M5cKGyvV8F\n",
            "We want controlled immigration that contributes positively to the UK economy. Same as Australia &amp; Canada. https://t.co/99mYliuOes\n",
            "Is the new Manitoba immigration fee a head tax? https://t.co/LsG7C3vLe9\n",
            "Canada immigration profit influence modernistic delhi yet abhinav: XKofy https://t.co/becgusY2i6\n",
            "Canada Immigration Minister to ���Substantially Increase  Immigration Numbers https://t.co/nEFw30MRaa https://t.co/cyI867PZRV\n",
            "M��me les #USA=pays d'immigration par excellence CONTR��LE RIGOUREUSEMENT l'immigration et acc��s �� la #GreenCARD!��_ https://t.co/IHpVhW2BaG\n",
            "@Shawhelp what changes should be made to Canada's immigration laws due to the influx of immigration and violence?\n",
            "L��immigration irr��guli��re au Canada d��cortiqu��e en 5 questions https://t.co/f4utO5A7ZF\n",
            "L'immigration irr��guli��re au Canada d��cortiqu��e en 5 questions - https://t.co/UiBsEZOqas https://t.co/j77dEvjoiX https://t.co/XXDeIG7Dbu\n",
            "Will Media ask the Liberals if they actually have a solid plan for Canada _��_�_?? From my view -- immigration out of C��_ https://t.co/YAgwmZ8ECp\n",
            "Dan Murray of��Immigration Watch Canada is xenophobic racist fear-mongering liar #racism #canada #cdnpoli #hatecrime��_ https://t.co/kwZ3csvYxM\n",
            "Le Canada lance une vaste campagne d'immigration pour faire face �� son besoin de main d'��uvre https://t.co/kXdfMGTZzN\n",
            "L��#immigration irr��guli��re au #Canada d��cortiqu��e en 5��questions https://t.co/s3hu1OKKIG\n",
            "@Canadidly I've read the Immigration laws of Canada much stricter than the US\n",
            "Canada Immigration Website Traffic Surges And Crashes In Wake Of Trump #fasttraffic,#sitetraffic,#website,#traffic https://t.co/zRlJ26jnkC\n",
            "Mr Know-all of Canada Immigration https://t.co/wTQK4QDiKI\n",
            "Move to Canada @LadyMadonna___ Oh, immigration rules, you can't... https://t.co/5LIEVHO7A4\n",
            "#OnThisDay Annette Toft becomes Canada's 2 millionth immigrant since 1945. Do you know your family's immigration st��_ https://t.co/UvRuw8eR1b\n",
            ".@TheEconomist profiles Canada's open immigration policies &amp; how they contribute to our economic success:��_ https://t.co/4K84EE8Y63\n",
            "Hundreds may lose Canadian citizenship, resident status because of one corrupt immigration consultant https://t.co/x2IfO0EXI2\n",
            "Immigration for canada without india: an compassionate handle: deyFy\n",
            "\"#Jamaican #immigrants #Canada\n",
            "\n",
            "https://t.co/vcmfYGadR5\n",
            "\n",
            "#statistics #immigration\"\n",
            "Mexican visa lift expected to cost Canada $262M over a decade https://t.co/9i72fRhtij\n",
            "Are people still moving to #Canada ??? Oh that's right, they have real immigration laws and it's��_ https://t.co/0C5OBfmxLG\n",
            "Here are more details on the Richmond, B.C. Immigration Consultant Sunny Wang who was sentenced to 7 years in... https://t.co/YXH5W53srO\n",
            "I added a video to a @YouTube playlist https://t.co/CnEyWN40x3 Funny Talking of Haryanavi Jat with Canada Immigration Girl Agent\n",
            "Mexicans Can Now Travel Visa-Free To Canada https://t.co/Ec3XHORO2s https://t.co/RQRr5nebcG\n",
            "L��immigration irr��guli��re au Canada d��cortiqu��e en 5��questions https://t.co/DkpuKyWmaK\n",
            "@SweetnessShawnB Hes the POS that ramped up immigration for Canada, among other globalist policies.\n",
            "Canada lifted visa requirements to Mexico as of Dec 1, 2016. Thoughts? #visa #immigration\n",
            "@HuffingtonPost people Keep praising Canada and Canada has way stricter immigration laws then us they willl boot your liberal American ass\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "----------------  Twitter content after lemmatization  ------------------------\n",
            "------------------------------------------------------------------------------- \n",
            "\n",
            "Reminds me of Liberal Immigration Fraudster Monsef avoiding deportation from Canada . # cdnpoli # LPC # CPCLDR��_ http : //t.co/ZOZOSe1CqQ # immigration # integration # canada http : //t.co/M5cKGyvV8F We want controlled immigration that contributes positively to the UK economy . Same a Australia & amp ; Canada . http : //t.co/99mYliuOes Is the new Manitoba immigration fee a head tax ? http : //t.co/LsG7C3vLe9 Canada immigration profit influence modernistic delhi yet abhinav : XKofy http : //t.co/becgusY2i6 Canada Immigration Minister to ���Substantially Increase Immigration Numbers http : //t.co/nEFw30MRaa http : //t.co/cyI867PZRV M��me le # USA=pays d'immigration par excellence CONTR��LE RIGOUREUSEMENT l'immigration et acc��s �� la # GreenCARD ! ��_ http : //t.co/IHpVhW2BaG @ Shawhelp what change should be made to Canada 's immigration law due to the influx of immigration and violence ? L��immigration irr��guli��re au Canada d��cortiqu��e en 5 question http : //t.co/f4utO5A7ZF L'immigration irr��guli��re au Canada d��cortiqu��e en 5 question - http : //t.co/UiBsEZOqas http : //t.co/j77dEvjoiX http : //t.co/XXDeIG7Dbu Will Media ask the Liberals if they actually have a solid plan for Canada _��_�_ ? ? From my view -- immigration out of C��_ http : //t.co/YAgwmZ8ECp Dan Murray of��Immigration Watch Canada is xenophobic racist fear-mongering liar # racism # canada # cdnpoli # hatecrime��_ http : //t.co/kwZ3csvYxM Le Canada lance une vaste campagne d'immigration pour faire face �� son besoin de main d'��uvre http : //t.co/kXdfMGTZzN L�� # immigration irr��guli��re au # Canada d��cortiqu��e en 5��questions http : //t.co/s3hu1OKKIG @ Canadidly I 've read the Immigration law of Canada much stricter than the US Canada Immigration Website Traffic Surges And Crashes In Wake Of Trump # fasttraffic , # sitetraffic , # website , # traffic http : //t.co/zRlJ26jnkC Mr Know-all of Canada Immigration http : //t.co/wTQK4QDiKI Move to Canada @ LadyMadonna___ Oh , immigration rule , you ca n't ... http : //t.co/5LIEVHO7A4 # OnThisDay Annette Toft becomes Canada 's 2 millionth immigrant since 1945 . Do you know your family 's immigration st��_ http : //t.co/UvRuw8eR1b . @ TheEconomist profile Canada 's open immigration policy & amp ; how they contribute to our economic success : ��_ http : //t.co/4K84EE8Y63 Hundreds may lose Canadian citizenship , resident status because of one corrupt immigration consultant http : //t.co/x2IfO0EXI2 Immigration for canada without india : an compassionate handle : deyFy '' # Jamaican # immigrant # Canada http : //t.co/vcmfYGadR5 # statistic # immigration '' Mexican visa lift expected to cost Canada $ 262M over a decade http : //t.co/9i72fRhtij Are people still moving to # Canada ? ? ? Oh that 's right , they have real immigration law and it's��_ http : //t.co/0C5OBfmxLG Here are more detail on the Richmond , B.C . Immigration Consultant Sunny Wang who wa sentenced to 7 year in ... http : //t.co/YXH5W53srO I added a video to a @ YouTube playlist http : //t.co/CnEyWN40x3 Funny Talking of Haryanavi Jat with Canada Immigration Girl Agent Mexicans Can Now Travel Visa-Free To Canada http : //t.co/Ec3XHORO2s http : //t.co/RQRr5nebcG L��immigration irr��guli��re au Canada d��cortiqu��e en 5��questions http : //t.co/DkpuKyWmaK @ SweetnessShawnB Hes the POS that ramped up immigration for Canada , among other globalist policy . Canada lifted visa requirement to Mexico a of Dec 1 , 2016 . Thoughts ? # visa # immigration @ HuffingtonPost people Keep praising Canada and Canada ha way stricter immigration law then u they willl boot your liberal American as\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ud-xAS5pToxg"
      },
      "source": [
        "## **Stemming**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5e_8GGGQdcl"
      },
      "source": [
        "#required libraries for Stemmer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "  \n",
        "porterStemmer = PorterStemmer()"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7L3pNmWdQ-qL"
      },
      "source": [
        "stemmed_student_feedback = porterStemmer.stem(student_feedback_content) \n",
        "stemmed_twitter_content = porterStemmer.stem(twitter_content)\n",
        "stemmed_research_paper_content = porterStemmer.stem(research_paper_content)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2lrwpj2Rdt9",
        "outputId": "4583af54-a77c-438d-d935-485f7035748c"
      },
      "source": [
        "print(\"------------------------------------------------------------------------------- \")\n",
        "print(\"--------------  Research paper content before lemmatization  -----------------\")\n",
        "print(\"------------------------------------------------------------------------------- \\n\")\n",
        "print(research_paper_content + '\\n')\n",
        "print(\"-------------------------------------------------------------------------------\")\n",
        "print(\"--------------  Research paper content after lemmatization  -------------------\")\n",
        "print(\"------------------------------------------------------------------------------- \\n\")\n",
        "print(stemmed_research_paper_content)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------------- \n",
            "--------------  Research paper content before lemmatization  -----------------\n",
            "------------------------------------------------------------------------------- \n",
            "\n",
            "Neural network models have shown their promising opportunities for multi-task\n",
            "learning, which focus on learning the shared layers to extract the common and\n",
            "task-invariant features. However, in most existing approaches, the extracted shared\n",
            "features are prone to be contaminated by task-specific features or the noise brought\n",
            "by other tasks. In this paper, we propose an adversarial multi-task learning framework,\n",
            "alleviating the shared and private latent feature spaces from interfering with\n",
            "each other. We conduct extensive experiments on 16 different text classification\n",
            "tasks, which demonstrates the benefits of our approach. Besides, we show that the\n",
            "shared knowledge learned by our proposed model can be regarded as off-the-shelf\n",
            "knowledge and easily transferred to new tasks.\n",
            "\n",
            "Multi-task learning is an effective approach to improve the performance of a single task with\n",
            "the help of other related tasks. Recently, neural-based models for multi-task learning have become\n",
            "very popular, ranging from computer vision (Misra et al., 2016; Zhang et al., 2014) to natural\n",
            "language processing (Collobert andWeston, 2008; Luong et al., 2015), since they provide a convenient\n",
            "way of combining information from multiple tasks.\n",
            "However, most existing work on multi-task learning (Liu et al., 2016c,b) attempts to divide the\n",
            "features of different tasks into private and shared spaces, merely based on whether parameters of some components should be shared. As shown in Figure 1-(a), the general shared-private model introduces\n",
            "two feature spaces for any task: one is used to store task-dependent features, the other is\n",
            "used to capture shared features. The major limitation of this framework is that the shared feature\n",
            "space could contain some unnecessary task-specific features, while some sharable features\n",
            "could also be mixed in private space, suffering from feature redundancy.\n",
            "Taking the following two sentences as examples, which are extracted from two different sentiment\n",
            "classification tasks: Movie reviews and Baby products reviews.\n",
            "The infantile cart is simple and easy to use. This kind of humour is infantile and boring.\n",
            "The word �infantile� indicates negative sentiment in Movie task while it is neutral in Baby task.\n",
            "However, the general shared-private model could place the task-specific word �infantile� in a\n",
            "shared space, leaving potential hazards for other tasks. Additionally, the capacity of shared space\n",
            "could also be wasted by some unnecessary features.\n",
            "To address this problem, in this paper we propose an adversarial multi-task framework, in\n",
            "which the shared and private feature spaces are in herently disjoint by introducing orthogonality constraints.Specifically, we design a generic shared private learning framework to model the text sequence.\n",
            "\n",
            "-------------------------------------------------------------------------------\n",
            "--------------  Research paper content after lemmatization  -------------------\n",
            "------------------------------------------------------------------------------- \n",
            "\n",
            "neural network models have shown their promising opportunities for multi-task\n",
            "learning, which focus on learning the shared layers to extract the common and\n",
            "task-invariant features. however, in most existing approaches, the extracted shared\n",
            "features are prone to be contaminated by task-specific features or the noise brought\n",
            "by other tasks. in this paper, we propose an adversarial multi-task learning framework,\n",
            "alleviating the shared and private latent feature spaces from interfering with\n",
            "each other. we conduct extensive experiments on 16 different text classification\n",
            "tasks, which demonstrates the benefits of our approach. besides, we show that the\n",
            "shared knowledge learned by our proposed model can be regarded as off-the-shelf\n",
            "knowledge and easily transferred to new tasks.\n",
            "\n",
            "multi-task learning is an effective approach to improve the performance of a single task with\n",
            "the help of other related tasks. recently, neural-based models for multi-task learning have become\n",
            "very popular, ranging from computer vision (misra et al., 2016; zhang et al., 2014) to natural\n",
            "language processing (collobert andweston, 2008; luong et al., 2015), since they provide a convenient\n",
            "way of combining information from multiple tasks.\n",
            "however, most existing work on multi-task learning (liu et al., 2016c,b) attempts to divide the\n",
            "features of different tasks into private and shared spaces, merely based on whether parameters of some components should be shared. as shown in figure 1-(a), the general shared-private model introduces\n",
            "two feature spaces for any task: one is used to store task-dependent features, the other is\n",
            "used to capture shared features. the major limitation of this framework is that the shared feature\n",
            "space could contain some unnecessary task-specific features, while some sharable features\n",
            "could also be mixed in private space, suffering from feature redundancy.\n",
            "taking the following two sentences as examples, which are extracted from two different sentiment\n",
            "classification tasks: movie reviews and baby products reviews.\n",
            "the infantile cart is simple and easy to use. this kind of humour is infantile and boring.\n",
            "the word �infantile� indicates negative sentiment in movie task while it is neutral in baby task.\n",
            "however, the general shared-private model could place the task-specific word �infantile� in a\n",
            "shared space, leaving potential hazards for other tasks. additionally, the capacity of shared space\n",
            "could also be wasted by some unnecessary features.\n",
            "to address this problem, in this paper we propose an adversarial multi-task framework, in\n",
            "which the shared and private feature spaces are in herently disjoint by introducing orthogonality constraints.specifically, we design a generic shared private learning framework to model the text sequence.\n"
          ]
        }
      ]
    }
  ]
}